{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport os","metadata":{"execution":{"iopub.status.busy":"2023-03-21T01:18:18.289855Z","iopub.execute_input":"2023-03-21T01:18:18.290275Z","iopub.status.idle":"2023-03-21T01:18:18.314871Z","shell.execute_reply.started":"2023-03-21T01:18:18.290240Z","shell.execute_reply":"2023-03-21T01:18:18.313591Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def data_generator(directories_number,list_len):\n\n    \n    directories = os.listdir('/kaggle/input/icecube-neutrinos-in-deep-ice/train/')\n    directories = directories[:directories_number]#temporal, indica cuantos batches se van a tomar\n    directories = [('/kaggle/input/icecube-neutrinos-in-deep-ice/train/')+x for i, x in enumerate(directories)]\n    \n    data = pd.DataFrame()\n    \n    \n    for file in directories:\n        temp = pd.read_parquet(file)\n        \n        temp = temp.sort_values('charge',ascending = False).groupby('event_id').head(list_len)\n        # al poner el head en 100 se reduciria la tabla en un 98%\n    \n        data = pd.concat([data, temp], axis=0)\n        \n    \n    #data = data.drop_duplicates()##\n    \n    coords = pd.read_csv('/kaggle/input/icecube-neutrinos-in-deep-ice/sensor_geometry.csv')\n    train_meta = pd.read_parquet('/kaggle/input/icecube-neutrinos-in-deep-ice/train_meta.parquet')\n    \n    data['event'] = data.index\n    \n    \n    data = pd.merge(data, train_meta[['event_id', 'azimuth', 'zenith']], left_on=data['event'], right_on=train_meta['event_id'].astype(float))\n    \n    data = pd.merge(data, coords, on='sensor_id', how='outer')\n\n\n     \n    data = pd.concat([\n        data.groupby('event').agg({'time': lambda x: list(x)}),\n        data.groupby('event').agg({'charge': lambda x: list(x)}),\n        data.groupby('event').agg({'x': lambda x: list(x)}),\n        data.groupby('event').agg({'y': lambda x: list(x)}),\n        data.groupby('event').agg({'z': lambda x: list(x)}),\n        data.groupby('event')['azimuth'].apply(min),\n        data.groupby('event')['zenith'].apply(min)\n        ],axis=1)\n    \n\n    data['time'] = data['time'].map(lambda a: a + [0] * (list_len - len(a)))\n    data['charge'] = data['charge'].map(lambda a: a + [0] * (list_len - len(a)))\n    data['x'] = data['x'].map(lambda a: a + [0] * (list_len - len(a)))\n    data['y'] = data['y'].map(lambda a: a + [0] * (list_len - len(a)))\n    data['z'] = data['z'].map(lambda a: a + [0] * (list_len - len(a)))\n    \n    return data[['time','charge','x','y','z','azimuth','zenith']]\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-20T12:50:18.682776Z","iopub.execute_input":"2023-03-20T12:50:18.683633Z","iopub.status.idle":"2023-03-20T12:50:18.700016Z","shell.execute_reply.started":"2023-03-20T12:50:18.683583Z","shell.execute_reply":"2023-03-20T12:50:18.698590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data_generator(3,15)","metadata":{"execution":{"iopub.status.busy":"2023-03-20T12:50:18.727088Z","iopub.execute_input":"2023-03-20T12:50:18.727513Z","iopub.status.idle":"2023-03-20T12:54:46.210385Z","shell.execute_reply.started":"2023-03-20T12:50:18.727474Z","shell.execute_reply":"2023-03-20T12:54:46.209309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \nimport keras","metadata":{"execution":{"iopub.status.busy":"2023-03-20T12:55:30.195552Z","iopub.execute_input":"2023-03-20T12:55:30.196630Z","iopub.status.idle":"2023-03-20T12:55:39.738837Z","shell.execute_reply.started":"2023-03-20T12:55:30.196588Z","shell.execute_reply":"2023-03-20T12:55:39.737590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"size = 0.25\nepoch = 15\n\ntest_size = int(round((len(data)*size),0))\ndata.sample(frac=1)\n\n\nX = data[['time','charge','x','y','z']]\ny_az = data['azimuth']\ny_ze = data['zenith']\n\n\nnum_cols = len(X.columns)\nnum_rows = len(X)\nres = list(X.sum(axis=1).to_numpy())\nres = np.reshape(res, (num_rows, num_cols, -1))\nX = res\n\n\nX_train = X[test_size:]\nX_test = X[:test_size]\n\ny_az_train = y_az.iloc[test_size:]\ny_az_test = y_az.iloc[:test_size]\n\ny_ze_train = y_ze.iloc[test_size:]\ny_ze_test = y_ze.iloc[:test_size]\n","metadata":{"execution":{"iopub.status.busy":"2023-03-20T12:55:39.741162Z","iopub.execute_input":"2023-03-20T12:55:39.742011Z","iopub.status.idle":"2023-03-20T12:55:42.093883Z","shell.execute_reply.started":"2023-03-20T12:55:39.741964Z","shell.execute_reply":"2023-03-20T12:55:42.092682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input = keras.Input(shape=(5, 15, ))\n\nx = keras.layers.Flatten()(input)\nx = keras.layers.BatchNormalization()(x)\n\nxa = keras.layers.Dense(16, activation='relu')(x)\nxa = keras.layers.Dense(16, activation='relu')(xa)\nxa = keras.layers.Dense(8, activation='relu')(xa)\n\nxz = keras.layers.Dense(16, activation='relu')(x)\nxz = keras.layers.Dense(16, activation='relu')(xz)\nxz = keras.layers.Dense(8, activation='relu')(xz)\n\nout_az = keras.layers.Dense(1, activation='linear', name='az-out')(xa)\nout_ze = keras.layers.Dense(1, activation='linear', name='ze-out')(xz)\n\n\nmodel = keras.Model( inputs = input, outputs = [out_az, out_ze])\n\n\nmodel.compile(\n    loss = {\n        'az-out': tf.keras.losses.MeanAbsoluteError(),\n        'ze-out': tf.keras.losses.MeanAbsoluteError(),\n    },\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0004))\n    \n        \n    \nhistory = model.fit(x=X_train,\n            y={\n                'az-out': y_az_train,\n                'ze-out': y_ze_train\n            },\n            validation_data=(X_test,             \n            {\n                'az-out': y_az_test,\n                'ze-out': y_ze_test\n            }),\n              epochs=epoch,verbose=1)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-03-20T12:55:42.095675Z","iopub.execute_input":"2023-03-20T12:55:42.096482Z","iopub.status.idle":"2023-03-20T13:03:06.520952Z","shell.execute_reply.started":"2023-03-20T12:55:42.096434Z","shell.execute_reply":"2023-03-20T13:03:06.519813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# az-out_loss: 1.5651 - ze-out_loss: 0.5711\n# az-out_loss: 1.5721 - ze-out_loss: 0.5747\n# az-out_loss: 3.1406 - ze-out_loss: 1.5342","metadata":{"execution":{"iopub.status.busy":"2023-03-20T12:18:58.224266Z","iopub.status.idle":"2023-03-20T12:18:58.224670Z","shell.execute_reply.started":"2023-03-20T12:18:58.224465Z","shell.execute_reply":"2023-03-20T12:18:58.224486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_test(list_len):\n    \n    directories = os.listdir('/kaggle/input/icecube-neutrinos-in-deep-ice/test/')\n    directories = directories[:2]#temporal, indica cuantos batches se van a tomar\n    directories = [('/kaggle/input/icecube-neutrinos-in-deep-ice/test/')+x for i, x in enumerate(directories)]\n    \n    data = pd.DataFrame()\n    \n    \n    for file in directories:\n        temp = pd.read_parquet(file)\n        \n        temp = temp.sort_values('charge',ascending = False).groupby('event_id').head(list_len)\n        # al poner el head en 100 se reduciria la tabla en un 98%\n    \n        data = pd.concat([data, temp], axis=0)\n        \n    \n    #data = data.drop_duplicates()##\n    \n    coords = pd.read_csv('/kaggle/input/icecube-neutrinos-in-deep-ice/sensor_geometry.csv')\n    \n    data['event_id'] = data.index\n    \n    data = pd.merge(data, coords, on='sensor_id', how='outer')\n\n     \n    data = pd.concat([\n        data.groupby('event_id').agg({'event_id': lambda x: min(x)}),\n        data.groupby('event_id').agg({'time': lambda x: list(x)}),\n        data.groupby('event_id').agg({'charge': lambda x: list(x)}),\n        data.groupby('event_id').agg({'x': lambda x: list(x)}),\n        data.groupby('event_id').agg({'y': lambda x: list(x)}),\n        data.groupby('event_id').agg({'z': lambda x: list(x)})\n        ],axis=1)\n    \n    \n    data['time'] = data['time'].map(lambda a: a + [0] * (list_len - len(a)))\n    data['charge'] = data['charge'].map(lambda a: a + [0] * (list_len - len(a)))\n    data['x'] = data['x'].map(lambda a: a + [0] * (list_len - len(a)))\n    data['y'] = data['y'].map(lambda a: a + [0] * (list_len - len(a)))\n    data['z'] = data['z'].map(lambda a: a + [0] * (list_len - len(a)))\n    \n\n    return data[['event_id','time','charge','x','y','z']]","metadata":{"execution":{"iopub.status.busy":"2023-03-20T20:43:15.073430Z","iopub.execute_input":"2023-03-20T20:43:15.073875Z","iopub.status.idle":"2023-03-20T20:43:15.088211Z","shell.execute_reply.started":"2023-03-20T20:43:15.073840Z","shell.execute_reply":"2023-03-20T20:43:15.086633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = data_test(15)","metadata":{"execution":{"iopub.status.busy":"2023-03-20T20:43:15.291455Z","iopub.execute_input":"2023-03-20T20:43:15.291882Z","iopub.status.idle":"2023-03-20T20:43:15.467086Z","shell.execute_reply.started":"2023-03-20T20:43:15.291847Z","shell.execute_reply":"2023-03-20T20:43:15.465552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_event = test_data[['time','charge','x','y','z']]\n\nnum_cols = len(not_event.columns)\nnum_rows = len(not_event)\nres = list(not_event.sum(axis=1).to_numpy())\nres = np.reshape(res, (num_rows, num_cols, -1))\n","metadata":{"execution":{"iopub.status.busy":"2023-03-20T20:43:17.571332Z","iopub.execute_input":"2023-03-20T20:43:17.572254Z","iopub.status.idle":"2023-03-20T20:43:17.583428Z","shell.execute_reply.started":"2023-03-20T20:43:17.572160Z","shell.execute_reply":"2023-03-20T20:43:17.581169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pred_az, pred_ze = model.predict(test_data[['time', 'charge', 'x', 'y', 'z']])\n#test_data[['azimuth', 'zenith']] = model.predict(test_data[['time', 'charge', 'x', 'y', 'z']])\npred_az, pred_ze = model.predict(res)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#idd = test_data['event_id']\n#submit = pd.concat([idd, pred_az, pred_ze], axis=1)\n\npred_az = pred_az.flatten()\npred_ze = pred_ze.flatten()\n\nsubmit = pd.DataFrame()\nsubmit['event_id'] = test_data['event_id'].astype('int')\nsubmit['azimuth'] = pred_az.tolist()\nsubmit['zenith'] = pred_ze.tolist()\nsubmit = submit.reset_index(drop=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_data[['event_id','azimuth','zenith']].to_parquet('submission.parquet')\nsubmit.to_csv('submission.csv')","metadata":{},"execution_count":null,"outputs":[]}]}